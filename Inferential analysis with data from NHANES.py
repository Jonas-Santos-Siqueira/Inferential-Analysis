# -*- coding: utf-8 -*-
"""Inferências.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GEOwv7ac_ymrCrszQ9mywe7co-k4Nb7A
"""

pip install dataprep

pip install plotly

pip install Dash

import dash
import pandas as pd
import numpy as np
import seaborn as sns
import dataprep
import matplotlib.pyplot as plt
from dataprep.eda import plot_correlation
from dataprep.datasets import load_dataset
from dataprep.eda import plot
from dataprep.eda import plot_diff
from dataprep.eda.missing import plot_missing

demo = pd.read_csv('DEMO_PHQ.csv')
pag_hei = pd.read_csv('PAG_HEI.csv')

demo.info()

demo.head(10)

pag_hei.info() #9424 observações de crianças e adultos.

pag_hei.head(10)

plot(pag_hei, "PAG_MINW")

jt = demo.merge(pag_hei, how = 'left',  on = 'SEQN')
jt.info()

"""###VISUALIZANDO DADOS FALTANTES:"""

# Primeira forma de ver os dados faltantes
jt.isnull().sum()

# Segunda forma de ver os dados faltantes
jt.isnull().mean().round(4)*100

jt.drop(columns=['SEQN']).describe(percentiles =[.25, .5, .75, .95, .99]).round(2)

plot_correlation(jt)

# Por curiosidade, irei visualizar a correlação do novo "df" com a ferramenta "DataPrep"
# Vemos aqui, que tem uma correção legal entre as variaveis ""DPQ010" a ""DPQ090", abrindo sentido para análisar essas variáveis depois.

jt[[
"DPQ010",
"DPQ020",
"DPQ030",
"DPQ040",
"DPQ050",
"DPQ060",
"DPQ070",
"DPQ080",
"DPQ090"]].agg(['value_counts'])

"""###A PARTI DE AGORA, COMEÇA UMA VISUALIZAÇÃO DE VARIÁVEIS. - PARTE 1.

nota: Estuda essa por## Jonas!

Visualizando detalhes das Variaveis "RIDRETH1", "RIAGENDR", "RIDAGEYR", "INDFMINC", "DMDEDUC", "ADHERENCE".


"""

jt[["RIAGENDR"]].value_counts(sort = False)

# Tem um numero maior de pessoas no publico feminino, entorno de 2773.

jt[["RIDAGEYR"]].value_counts(sort = False)

plot(jt, "RIDAGEYR")

# Vemos aqui a distribuição das idades.
# A media de idade é entorno de 43 a 45 anos.

jt[["INDFMINC"]].value_counts(sort = False)

# 'Renda maior ou igual a 75.000' tem a maior concentração de pessoas.

jt[["DMDEDUC"]].value_counts(sort = False)

# o primeiro grupo com mais pessoas é o "4", onde é esperado que essas pessoas estejam no "Esino Superior"
# O segundo grupo com mais pessoas é o "3", que seria os jovens no "Ensino Médio#
# Mas iremos desconsidera do 1 ao 3 (por enquanto) por conta dessa atividade ter o foco apénas no publico alvo#

jt[["RIDRETH1"]].value_counts(sort = False)

# O maior numero de pessoas é "Mexicano-Americano" no grupo "3".
# O Segundo maior grupo de pessoas é "Outros" no grupo "4".
# Terceiro maior grupo de pessoas são "Brancas" no grupo "1".
# Os negros são o menor grupo dessa Variavel.

"""###Agrupando e recategorizando variáveis qualitativas:

Nota: Estudar mais sobre como fazer.

Nota2: Eu estudei e vou aderir essa forma, achei NICE!!

Eu estudei uma forma de retirar as informações "1", "2" e "3" da Variavel "DMDEDUC", porém os metodos ".drop", ".shape" e entre outros não seria muito viavel nesse caso, então a função "replace_map" é a mais indicada e recomendada. Irei estudar e entender mais sobre tal função.
"""

replace_map = {
  "DPQ010": {7: np.nan, 9: np.nan},
  "DPQ020": {7: np.nan, 9: np.nan},
  "DPQ030": {7: np.nan, 9: np.nan},
  "DPQ040": {7: np.nan, 9: np.nan},
  "DPQ050": {7: np.nan, 9: np.nan},
  "DPQ060": {7: np.nan, 9: np.nan},
  "DPQ070": {7: np.nan, 9: np.nan},
  "DPQ080": {7: np.nan, 9: np.nan},
  "DPQ090": {7: np.nan, 9: np.nan},
  "RIDRETH1": {5: 2},
  "DMDEDUC": {7: np.nan, 9: np.nan},
  "INDFMINC": {1: np.mean([0,4999]), 2: np.mean([5000,9999]), 3: np.mean([10000,14999]),4: np.mean([15000,19999]),
               5: np.mean([20000,24999]),6: np.mean([25000,34999]), 7: np.mean([35000,44999]), 8: np.mean([45000,54999]),
               9: np.mean([55000,64999]), 10: np.mean([65000,74999]), 11: np.mean([75000,95000]), 12: np.mean([20000, 90000]), 13: np.mean([0, 19999]),
               77: np.nan, 99: np.nan}
}

njt = jt.replace(replace_map)

plot(njt, "INDFMINC")

# O plot mostra os valores 'mean' de cada resposta para a pergunta feita na variável "INDFMINC".

njt[["INDFMINC"]].value_counts(sort = False)

njt[["RIDAGEYR"]].info()

njt[["DMDEDUC"]].isnull().mean().round(4)

# Vemos aqui que o valor "3" é o segundo maior em "Frequency", esse valor foi colocado com 'np.nan'.

plot(njt, "DMDEDUC")

"""
# Criação das Variáveis."""

# Checando os valores nulos do novo DataBase    
njt.isnull().mean().round(4)*100

"""."""

njt[["DPQ010", "DPQ020", "DPQ030", "DPQ040", "DPQ050", "DPQ060", "DPQ070", "DPQ080", "DPQ090"]].isnull().mean()*100

njt["phq9"] = njt[["DPQ010", 
                   "DPQ020", 
                   "DPQ030", 
                   "DPQ040", 
                   "DPQ050", 
                   "DPQ060", 
                   "DPQ070", 
                   "DPQ080", 
                   "DPQ090"]].sum(axis = 'columns', skipna = False)

njt[["DPQ010", 
     "DPQ020", 
     "DPQ030", 
     "DPQ040",
     "DPQ050", 
     "DPQ060", 
     "DPQ070", 
     "DPQ080", 
     "DPQ090",
     "phq9"]].head(10)

# Olhando como ficou todo o banco de dados do novo database.

njt.head()

"""Agora, criar a varivel de grupo PHQ_GRP

------------------------------------------------------------------------------

Criando a variável phq_grp - grupo de sintomas de depressão que assume 0 (“sem sintomas”) se phq9 < 5, 1 (“sintomas leves”) se 5 <= phq9 < 10, 2 (“sintomas moderados”) se 10 <= phq9 < 15, 3 (“sintomas moderadamente severos”) se 15 <= phq9 < 19 e 4 (“sintomas severos”) se phq9 >= 20
"""

conditions = [
  (njt['phq9'].isna()),
  (njt['phq9'] < 5),
  (njt['phq9'] <= 5) & (njt['phq9'] < 10),
  (njt['phq9'] <= 10) & (njt['phq9'] < 15),
  (njt['phq9'] <= 15) & (njt['phq9'] < 19),
  (njt['phq9'] >= 19)
    ]
values = [np.nan, 0, 1, 2, 3, 4]

njt["phq_grp"] = np.select(conditions, values)

njt[["phq_grp"]].value_counts(sort = False)

plot(njt, "phq_grp")

njt[["phq_grp"]].isnull().mean().round(4)*100

njt[["phq_grp"]].value_counts(sort = False)

plot(njt, "phq_grp")

"""### ANÁLISE UNIVARIADA 

será usado a variável "phq_grp".
"""

var_quant = [
    "RIDAGEYR", 
    "INDFMINC", 
    "PAG_MINW", 
    "HEI2015C1_TOTALVEG",
    "HEI2015C2_GREEN_AND_BEAN",
    "HEI2015C3_TOTALFRUIT",
    "HEI2015C4_WHOLEFRUIT",
    "HEI2015C5_WHOLEGRAIN",
    "HEI2015C6_TOTALDAIRY",
    "HEI2015C7_TOTPROT",
    "HEI2015C8_SEAPLANT_PROT",
    "HEI2015C9_FATTYACID",
    "HEI2015C10_SODIUM",
    "HEI2015C11_REFINEDGRAIN",
    "HEI2015C12_SFAT",
    "HEI2015C13_ADDSUG",
    "HEI2015_TOTAL_SCORE",
    "phq9"]

var_quali = [
    "RIAGENDR",
    "RIDRETH1",
    "DMDEDUC",
    "ADHERENCE",
    "phq_grp"
]

label_quali = {
  "RIAGENDR": {1: 'Masculino', 2: 'Feminino'},
  "RIDRETH1": {1: 'Americano Mexicano', 2: 'Outro', 3: 'Branco \n não hispânico', 4: 'Negro \n não hispânico'},
  "DMDEDUC": {1: "< 9 ano", 2: "9-12 ano", 3: "Ensino \n médio", 4: "Superior \n incompleto", 5: "Superior \n completo"},
  "ADHERENCE": {1: 'Baixo', 2: 'Adequado', 3: 'Acima'},
  "phq_grp": {0: "S/ Sint.", 1: "Sint. Leves", 2: "Sint. Mderados", 3: "Sint. MS" , 4: "Sint. Severos" }
}

njt[var_quant].describe(percentiles = [.25, .5, .75, .95, .99]).round(2)

"""Como foi instruido, o valor entre o "99%" e o "max" estão muito distantes, sendo assim um possivel "erro" - Irei fazer uma pesquisa em relação a esse valor e mudarei assim que tiver uma resposta.

Sera colocado atráves de uma função ("np.where") o valor de "3.600" (min) por semana para valores maiores que "3.600":
"""

njt['PAG_MINW_truco'] = np.where(njt['PAG_MINW'] > 3600, 3600, njt['PAG_MINW'])

# verificando se os valores estão corretos entre "99%" e "max", entre a variavel original ("PAG_MINW") e a nova variavel ("PAG_MINW_truco").

njt[['PAG_MINW', 'PAG_MINW_truco']].describe(percentiles = [.25, .5, .75, .95, .99]).round(2)

# Por curiosidade eu irei plota uma grafico mostrando alguns detalhes a mais sobre os "Percentile" da Variável "PAG_MINW_trunco"
# por conta de sua mudança para 3600 minutos (60h semanais)

sns.distplot(njt['PAG_MINW_truco'])
plt.axvline(x=np.percentile(njt['PAG_MINW_truco'],25), c='green', ls='--', label = '25th percentile:Q1')
plt.axvline(x=np.mean(njt['PAG_MINW_truco']), c='red', ls='--', label='mean')
plt.axvline(x=np.percentile(njt['PAG_MINW_truco'],75), c='purple', ls='--',label = '75th percentile:Q3' )
plt.axvline(x=np.percentile(njt['PAG_MINW_truco'],95), c='black', ls='--',label = '95th percentile:Q4' )
plt.axvline(x=np.percentile(njt['PAG_MINW_truco'],100), c='blue', ls='--',label = 'Max' )
plt.legend()

# Fazendo uma visualização de como está a "variável" "PAG_MINW_trunc".


plot(njt, "PAG_MINW_truco")

"""--------------------------------------------------------------------------------
Deixando os valores em minutos da variável "PAG_MINW_truco" em horas, porém mantendo a Variavel "PAG_MINW_truco "intacta":
"""

njt["PAG_HRW"] = njt["PAG_MINW_truco"]/60

sns.displot(njt, x="RIDAGEYR", kde=True)
sns.displot(njt, x="INDFMINC", kde=True)
sns.displot(njt, x="PAG_MINW_truco", kde=True)
sns.displot(njt, x="PAG_HRW", kde=True)
plt.show()

""":Como a variavel "PAG_HRW" é bastante assimétrica, será feito uma versão com log-normal:

Será feito na de minutos e horas (só para explorar mais a função "np.log")
"""

# Log-normal ná variável "PAG_HRW".

njt["PAG_HRW_log"] = np.log(njt["PAG_HRW"] + 1)

# Log-normal ná variável "PAG_MINW"

njt["PAG_MINW_log"] = np.log(njt["PAG_HRW"] + 1)

# Para uma melhor exploração, foi usado aqui um metodo para ter um grafico hist interativo
# da variável "PAG_HRW_log"

import plotly.figure_factory as ff

x = njt["PAG_HRW_log"]

hist_data = [x]
group_labels = ['PAG_HRW_log'] # name of the dataset
colors = ['slategray']

fig = ff.create_distplot(hist_data, group_labels, bin_size=.18, colors=colors, show_rug=False, curve_type='kde')
fig.show()

sns.displot(njt, x="PAG_HRW_log", kde=True)
plt.show()

# Visualizando a variavel "PAG_MINW_log" (minutos em vez de horas) para checar se ter alguma diferença.

sns.displot(njt, x="PAG_MINW_log", kde=True)
plt.show()

"""Criando uma função para plota graficos de Barra."""

import plotly.graph_objects as go

def grafico_barras_prop(data, variable):
    (data[[variable]]
     .value_counts(normalize=True, sort = False)
     .rename("Proportion")
     .reset_index()
     .pipe((sns.barplot, "data"), x=variable, y="Proportion"))
    plt.ylim(0,1)
    plt.show()

grafico_barras_prop(njt.replace(label_quali), variable = "RIAGENDR")

grafico_barras_prop(njt.replace(label_quali), variable = "RIDRETH1")

grafico_barras_prop(njt.replace(label_quali), variable = "DMDEDUC")

grafico_barras_prop(njt.replace(label_quali), variable = "ADHERENCE")

grafico_barras_prop(njt.replace(label_quali), variable = "phq_grp")

# Adiciono um grafico de distribuição para ter uma outra visão.
sns.scatterplot(njt[''], njt[''])

"""##ANÁLISE BIVARIADA"""

# Função para criar grafico box plot.
# Deixarei a formula aqui por enquanto.

def grafico_boxplot_grp(data, variable, label):
    
    if label == "": label = variable
    sns.boxplot(x="phq_grp", y=variable, data=data)
    plt.ylabel(label)
    plt.show()

# Plotando o grafico Box plot de forma simples com 

grafico_boxplot_grp(njt.replace(label_quali), "RIDAGEYR", "Idade")

# Plotando o grafico Box Plot de uma forma mais elaborada.

import plotly.express as px
db = px.data.tips()
fig = px.box(njt.replace(label_quali), x="phq_grp", y="RIDAGEYR", points="all")
fig.show()

"""--------------------------------------------------------------------------------
Teste de Hipótese: 
"""

from scipy.stats import f_oneway

db_aux = njt[["phq_grp", "RIDAGEYR"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.phq_grp == 0)]["RIDAGEYR"],
                   db_aux[(db_aux.phq_grp == 1)]["RIDAGEYR"],
                   db_aux[(db_aux.phq_grp == 2)]["RIDAGEYR"],
                   db_aux[(db_aux.phq_grp == 3)]["RIDAGEYR"],
                   db_aux[(db_aux.phq_grp == 4)]["RIDAGEYR"])

print('stat=%.3f, p=%.3f' % (stat, p))

db = px.data.tips()
fig = px.box(njt.replace(label_quali), x="phq_grp", y="INDFMINC", points="all")
fig.show()

"""------------------------------------"""

db_aux = njt[["phq_grp", "INDFMINC"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.phq_grp == 0)]["INDFMINC"],
                   db_aux[(db_aux.phq_grp == 1)]["INDFMINC"],
                   db_aux[(db_aux.phq_grp == 2)]["INDFMINC"],
                   db_aux[(db_aux.phq_grp == 3)]["INDFMINC"],
                   db_aux[(db_aux.phq_grp == 4)]["INDFMINC"])

print('stat=%.3f, p=%.3f' % (stat, p))

"""Análisar pontos a ser considerados: """

from statsmodels.stats.multicomp import pairwise_tukeyhsd

tukey = pairwise_tukeyhsd(db_aux['INDFMINC'],
                  db_aux['phq_grp'],
                  alpha = 0.05)
print(tukey)

#

db = px.data.tips()
fig = px.box(njt.replace(label_quali), x="phq_grp", y="INDFMINC", points="all")
fig.show()

db_aux = njt[["phq_grp", "PAG_HRW_log"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.phq_grp == 0)]["PAG_HRW_log"],
                   db_aux[(db_aux.phq_grp == 1)]["PAG_HRW_log"],
                   db_aux[(db_aux.phq_grp == 2)]["PAG_HRW_log"],
                   db_aux[(db_aux.phq_grp == 3)]["PAG_HRW_log"],
                   db_aux[(db_aux.phq_grp == 4)]["PAG_HRW_log"])

print('stat=%.3f, p=%.3f' % (stat, p))

"""Comparações multiplas:

Análisar pontos a ser considerados:
"""

from statsmodels.stats.multicomp import pairwise_tukeyhsd

tukey = pairwise_tukeyhsd(db_aux['PAG_HRW_log'],
                          db_aux['phq_grp'],
                          alpha = 0.05)

print(tukey)

db = px.data.tips()
fig = px.box(njt.replace(label_quali), x="phq_grp", y="PAG_HRW_log", points="all")
fig.show()

"""---------------

Análisar pontos a ser considerados:
"""

db_aux = njt[["phq_grp", "HEI2015_TOTAL_SCORE"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.phq_grp == 0)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.phq_grp == 1)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.phq_grp == 2)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.phq_grp == 3)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.phq_grp == 4)]["HEI2015_TOTAL_SCORE"])

print('stat=%.3f, p=%.3f' % (stat, p))

"""Comparações multiplas:"""

tukey = pairwise_tukeyhsd(db_aux['HEI2015_TOTAL_SCORE'],
                          db_aux['phq_grp'],
                          alpha = 0.05)
print(tukey)

db = px.data.tips()
fig = px.box(njt.replace(label_quali), x="phq_grp", y="HEI2015_TOTAL_SCORE", points="all")
fig.show()

"""-----------------------"""

db_aux = njt[["phq_grp", "RIDRETH1"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.phq_grp == 0)]["RIDRETH1"],
                   db_aux[(db_aux.phq_grp == 1)]["RIDRETH1"],
                   db_aux[(db_aux.phq_grp == 2)]["RIDRETH1"],
                   db_aux[(db_aux.phq_grp == 3)]["RIDRETH1"],
                   db_aux[(db_aux.phq_grp == 4)]["RIDRETH1"])

print('stat=%.3f, p=%.3f' % (stat, p))

tukey = pairwise_tukeyhsd(db_aux['RIDRETH1'],
                          db_aux['phq_grp'],
                          alpha = 0.05)
print(tukey)

db = px.data.tips()
fig = px.box(njt.replace(label_quali), x="phq_grp", y="RIDRETH1", points="all")
fig.show()

"""--------------------------

Bonus para eu aderir em minhas futuras análises:

Visualização em grafico entre Alimentação Saudável x Exercícios Físicos
"""

# fazer uma função com graficos interativos em base desse código.
sns.boxplot(y="ADHERENCE", 
            x="HEI2015_TOTAL_SCORE", 
            orient="h",
            data=njt.replace(label_quali))
plt.show()

fig, ax = plt.subplots(ncols=2, figsize=(15,5))

sns.regplot(x = 'HEI2015_TOTAL_SCORE', 
            y = 'PAG_HRW', 
            lowess=True, 
            line_kws={'color': 'red'},
            data = njt,
            ax = ax[0])

sns.regplot(x = 'HEI2015_TOTAL_SCORE', 
            y = 'PAG_HRW_log', 
            lowess=True, 
            line_kws={'color': 'red'},
            data = njt,
            ax = ax[1])
plt.show()

db_aux = njt[["ADHERENCE", "HEI2015_TOTAL_SCORE"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.ADHERENCE == 1)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.ADHERENCE == 2)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.ADHERENCE == 3)]["HEI2015_TOTAL_SCORE"])

print('stat=%.3f, p=%.3f' % (stat,p))

"""Comparações multiplas:"""

tukey = pairwise_tukeyhsd(db_aux['HEI2015_TOTAL_SCORE'],
                  db_aux['ADHERENCE'],
                  alpha = 0.05)

print(tukey)

db_aux = njt[["RIAGENDR", "PAG_HRW", "PAG_HRW_log", "HEI2015_TOTAL_SCORE"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.RIAGENDR == 1)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.RIAGENDR == 2)]["HEI2015_TOTAL_SCORE"])

print('stat=%.3f, p=%.3f' % (stat, p))

db_aux = njt[["RIAGENDR", "PAG_HRW", "PAG_HRW_log", "HEI2015_TOTAL_SCORE"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.RIAGENDR == 1)]["PAG_HRW_log"],
                   db_aux[(db_aux.RIAGENDR == 2)]["PAG_HRW_log"])

print('stat=%.3f, p=%.3f' % (stat, p))

db_aux = njt[["RIDRETH1", "PAG_HRW", "PAG_HRW_log", "HEI2015_TOTAL_SCORE"]].dropna()

stat, p = f_oneway(db_aux[(db_aux.RIDRETH1 == 1)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.RIDRETH1 == 2)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.RIDRETH1 == 3)]["HEI2015_TOTAL_SCORE"],
                   db_aux[(db_aux.RIDRETH1 == 4)]["HEI2015_TOTAL_SCORE"])

print('stat=%.3f, p=%.3f' % (stat, p))

tukey = pairwise_tukeyhsd(db_aux['HEI2015_TOTAL_SCORE'],
                  db_aux['RIDRETH1'],
                  alpha = 0.05)

print(tukey)

stat, p = f_oneway(db_aux[(db_aux.RIDRETH1 == 1)]["PAG_HRW_log"],
                   db_aux[(db_aux.RIDRETH1 == 2)]["PAG_HRW_log"],
                   db_aux[(db_aux.RIDRETH1 == 3)]["PAG_HRW_log"],
                   db_aux[(db_aux.RIDRETH1 == 4)]["PAG_HRW_log"])

print('stat=%.3f, p=%.3f' % (stat, p))

tukey = pairwise_tukeyhsd(db_aux['PAG_HRW_log'],
                  db_aux['RIDRETH1'],
                  alpha = 0.05)

print(tukey)